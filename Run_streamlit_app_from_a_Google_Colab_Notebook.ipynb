{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcsilva83/ChatGPT_Notebooks/blob/main/Run_streamlit_app_from_a_Google_Colab_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vWmc_s2ezvU0"
      },
      "source": [
        "# Run streamlit app from a Google Colab Notebook\n",
        "> Created by [Manuel Romero](https://twitter.com/mrm8488)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvlYkCQ9vFiy"
      },
      "source": [
        "!pip install -q streamlit"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "print(\"Password/Enpoint IP for localtunnel is:\",urllib.request.urlopen('https://ipv4.icanhazip.com').read().decode('utf8').strip(\"\\n\"))"
      ],
      "metadata": {
        "id": "an2C3c_0Ooi9",
        "outputId": "2f47247b-caf6-4e2b-f076-8056cff71308",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Password/Enpoint IP for localtunnel is: 34.125.44.53\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "OPENAI_API_KEY=sk-"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7FURLRL1R_5U",
        "outputId": "e461be5b-190d-497d-ad65-0b248f358459"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waCfwniZOow8"
      },
      "source": [
        "## Create a streamlit app example\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "from langchain.agents import create_csv_agent,initialize_agent, Tool\n",
        "#from langchain.chat_models import ChatOpenAI\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.callbacks import get_openai_callback\n",
        "from langchain.callbacks.streaming_stdout_final_only import FinalStreamingStdOutCallbackHandler\n",
        "from langchain.callbacks.base import AsyncCallbackHandler\n",
        "from IPython.display import Markdown, display\n",
        "from timeit import default_timer as timer\n",
        "import json\n",
        "# \"/Users/metro/Documents/Data & ChatGPT/gpt/bin/activate\"\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "from tempfile import NamedTemporaryFile\n",
        "\n",
        "from PIL import Image\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def main():\n",
        "    load_dotenv()\n",
        "\n",
        "    # Load the OpenAI API key from the environment variable\n",
        "    openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "    if not openai_api_key:\n",
        "        raise ValueError(\"OPENAI_API_KEY is not set\")\n",
        "\n",
        "    #st.set_page_config(page_title=\"Talk with your CSV üìä\")\n",
        "    st.set_page_config(\n",
        "        page_title=\"Talk with your CSV üìä\",\n",
        "        page_icon=\":bar_chart:\",\n",
        "        layout=\"wide\",\n",
        "        initial_sidebar_state=\"collapsed\",\n",
        ")\n",
        "    st.header(\"Start Ask to your CSV üìàü¶Ö\")\n",
        "    st.subheader('Make a question and let ChatGPT answer it for ya!! :sunglasses:')\n",
        "    #st.caption('A caption with _italics_ :blue[colors] and emojis :sunglasses:')\n",
        "    #logo = Image.open(\"header_Icon_sidebar.jpg\")\n",
        "    # https://ibb.co/7QPd3xD\n",
        "    #st.sidebar.image(logo, use_column_width=True)\n",
        "    # Using \"with\" notation\n",
        "    with st.sidebar:\n",
        "        \"## This is the sidebar\"\n",
        "\n",
        "\n",
        "        add_radio = st.radio(\n",
        "           \"Select a Model\",\n",
        "            (\"gpt-3.5-turbo\", \"text-davinci-003\",\"GPT-4\")\n",
        "\n",
        "        )\n",
        "\n",
        "\n",
        "        st.slider(\"Define the Temperature to be applied into the Agent model\",min_value=0.0, max_value=1.0, value=0.0, step=0.1)\n",
        "        #st.markdown(\"The next word is <span style='color:red'>red</span>\", unsafe_allow_html=True)\n",
        "        st.caption(\"**:black[_One intriguing parameter within LLMs is the ‚Äútemperature.‚Äù The LLM temperature is a hyperparameter that regulates the randomness, or creativity, of the AI‚Äôs responses. A higher temperature value typically makes the output more diverse and creative but might also increase its likelihood of straying from the context. Conversely, a lower temperature value makes the AI‚Äôs responses more focused and deterministic, sticking closely to the most likely prediction._]**\")\n",
        "        # Using object notation\n",
        "        add_selectbox = st.sidebar.selectbox( \"Which Agent would you like to use?\",(\"CSV\", \"Pandas\",\"Python\")\n",
        "    )\n",
        "    st.markdown(\"\"\"\n",
        "    <style>\n",
        "        [data-testid=stSidebar] {\n",
        "            background-color: #17FFE7 ;\n",
        "        }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "\n",
        "    # Define the variables\n",
        "    max_width = 1400\n",
        "    padding_top = 0.8\n",
        "    padding_right = 0.8\n",
        "    padding_left = 0.8\n",
        "    padding_bottom = 0.8\n",
        "    COLOR = \"#339933\"\n",
        "    BACKGROUND_COLOR = \"#F0F9F6\"\n",
        "\n",
        "    st.caption(f'You have select _{add_radio}_ to run within your ChatBot!! :sunglasses:')\n",
        "# Use the variables in the st.markdown code snippet\n",
        "    st.markdown(\n",
        "        f\"\"\"\n",
        "        <style>\n",
        "            .reportview-container .main .block-container {{\n",
        "                max-width: {max_width}px;\n",
        "                padding-top: {padding_top}rem;\n",
        "                padding-right: {padding_right}rem;\n",
        "                padding-left: {padding_left}rem;\n",
        "                padding-bottom: {padding_bottom}rem;\n",
        "            }}\n",
        "            .reportview-container .main {{\n",
        "                color: {COLOR};\n",
        "                background-color: {BACKGROUND_COLOR};\n",
        "            }}\n",
        "        </style>\n",
        "        \"\"\",\n",
        "        unsafe_allow_html=True,\n",
        "    )\n",
        "\n",
        "    user_csv = st.file_uploader(\"Please, upload your CSV file\", type=\"csv\")\n",
        "\n",
        "    if user_csv:\n",
        "        with NamedTemporaryFile() as f:\n",
        "            f.write(user_csv.getvalue())\n",
        "            if add_radio == \"text-davinci-003\":\n",
        "                llm = OpenAI(model_name=\"text-davinci-003\", temperature=0)\n",
        "            elif add_radio == \"GPT-4\" :\n",
        "                llm = OpenAI( temperature=0)\n",
        "            else:\n",
        "                llm = OpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
        "            #llm = OpenAI(model_name=\"\"text-ada-001\"\", temperature=0)\n",
        "            #llm = OpenAI( temperature=0)\n",
        "            user_input = st.text_input(\"Question here:\")\n",
        "\n",
        "            agent = create_csv_agent(llm, f.name, verbose=True)\n",
        "\n",
        "            with get_openai_callback() as cb:\n",
        "                if user_input:\n",
        "                    with st.spinner(text=\"In progress...\"):\n",
        "                        start = timer()\n",
        "                        output = agent.run(user_input)\n",
        "                        st.write(output)\n",
        "                        total_tokens = f\"Total Tokens: {cb.total_tokens}\"\n",
        "                        prompt_tokens = f\"Prompt Tokens: {cb.prompt_tokens}\"\n",
        "                        completion_tokens = f\"Completion Tokens: {cb.completion_tokens}\"\n",
        "                        total_cost = f\"Total Cost (USD): ${cb.total_cost:.5f}\"\n",
        "                        end = timer()\n",
        "                        calc = end - start\n",
        "                        with st.sidebar:\n",
        "                            with st.expander(\"Some stats about the AgentExecution\"):\n",
        "                                st.markdown(f\"Total Tokens: <span style='color:black'>{cb.total_tokens}</span>\", unsafe_allow_html=True)\n",
        "                                st.markdown(f\"Prompt Tokens:  <span style='color:black'>{cb.prompt_tokens}</span>\", unsafe_allow_html=True)\n",
        "                                st.markdown(f\"Completion Tokens:  <span style='color:black'>{cb.completion_tokens}</span>\", unsafe_allow_html=True)\n",
        "                                st.markdown(f\"Total Cost (USD): $ <span style='color:black'>{cb.total_cost:.5f}</span>\", unsafe_allow_html=True)\n",
        "                                st.markdown(f\"Runtime of the program was <span style='color:black'>{calc:.2f} seconds</span> seconds\", unsafe_allow_html=True)\n",
        "\n",
        "                        with st.expander(\"See explanation\"):\n",
        "                            st.write(agent.agent.llm_chain.prompt.template)\n",
        "                       ## with st.expander(\"See explanation_\"):\n",
        "                       ##     st.write(agent.agent)\n",
        "                       ## with st.expander(\"See explanation__\"):\n",
        "                       ##     st.write(agent.agent)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "meJ36PefNftd",
        "outputId": "864edca2-0f7f-4918-e6bc-17fb35aec7ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZlEJkmSOoxC"
      },
      "source": [
        "## Install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "518a7e9a-6ee4-44f9-f719-ccad65371383",
        "id": "ZAyqQCQVOoxC"
      },
      "source": [
        "!npm install localtunnel"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25h+ localtunnel@2.0.2\n",
            "updated 1 package and audited 36 packages in 1.22s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run streamlit in background"
      ],
      "metadata": {
        "id": "kccYE2lkN20y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/app.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "Zv912rRAN0fs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJvfITGvQWyW",
        "outputId": "7f403a2a-313b-4f79-aa6c-cfd40ced89ee"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.208)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.10)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.5.8)\n",
            "Requirement already satisfied: langchainplus-sdk>=0.0.13 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.16)\n",
            "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.22.4)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.27.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (23.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3oodsk6SRRfS",
        "outputId": "0f55248a-5f0b-4228-f0a2-70bc4ba4bf3c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Expose the port 8501\n",
        "Then just click in the `url` showed.\n",
        "\n",
        "A `log.txt`file will be created."
      ],
      "metadata": {
        "id": "h_KW9juhOCuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "XTGAizLhOIgC",
        "outputId": "72889220-e357-4c80-df6d-f5148ed0acfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.83s\n",
            "your url is: https://sixty-groups-vanish.loca.lt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVz-H__pOoxG"
      },
      "source": [
        "[![ko-fi](https://www.ko-fi.com/img/githubbutton_sm.svg)](https://ko-fi.com/Y8Y3VYYE)"
      ]
    }
  ]
}

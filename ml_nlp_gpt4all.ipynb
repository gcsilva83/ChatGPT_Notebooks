{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gcsilva83/ChatGPT_Notebooks/blob/main/ml_nlp_gpt4all.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tutorial of Natural Language Processing (GPT4ALL)"
      ],
      "metadata": {
        "id": "xFA3j06oUHVl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please get in touch if interested in our future collaboration of science and/or business!\\\n",
        "Daiphys Technologies LLC - https://www.daiphys.com/"
      ],
      "metadata": {
        "id": "wNjhHIT5XWqr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. References"
      ],
      "metadata": {
        "id": "JmRTsnWIVrIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- https://gpt4all.io/\n",
        "- https://docs.gpt4all.io/\n",
        "- https://github.com/nomic-ai/gpt4all/"
      ],
      "metadata": {
        "id": "GavwPd71VxbP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Preparation"
      ],
      "metadata": {
        "id": "ApanDCxUg4qk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Install"
      ],
      "metadata": {
        "id": "AvpQlPmXiYqT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Python\n",
        "!python --version"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ta9Ijc5urEvz",
        "outputId": "ced064cd-4c8b-400e-ba6d-db110881dbe6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get update"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DV8wlZ7QuUnH",
        "outputId": "1730ac85-0642-4b2e-e893-04e2d1cd5a99"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,014 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,803 kB]\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:13 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,359 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,063 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/restricted amd64 Packages [2,538 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,282 kB]\n",
            "Fetched 12.4 MB in 4s (3,254 kB/s)\n",
            "Reading package lists... Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade gpt4all"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJuvrbn_uZ16",
        "outputId": "c0d7a090-9d4a-4b7e-a5e1-18580bb99c58"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gpt4all\n",
            "  Downloading gpt4all-0.3.5-py3-none-manylinux1_x86_64.whl (2.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from gpt4all) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gpt4all) (4.65.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->gpt4all) (3.4)\n",
            "Installing collected packages: gpt4all\n",
            "Successfully installed gpt4all-0.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.2. Import"
      ],
      "metadata": {
        "id": "D5li2cg-tY_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip list\n",
        "#!pip freeze > requirements.txt"
      ],
      "metadata": {
        "id": "qOGO8NVlsQGw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gpt4all"
      ],
      "metadata": {
        "id": "KycJLf5UFnlK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.3. Setup"
      ],
      "metadata": {
        "id": "QkWDiuieFwkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Commercially Licensable Model\n",
        "#gptj = gpt4all.GPT4All('ggml-gpt4all-j-v1.3-groovy')"
      ],
      "metadata": {
        "id": "iE0zI1B4F4fS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-RdJXqxTOsHg",
        "outputId": "91dc82a8-a959-4c0c-81e4-e10e0011908f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Non-Commercially Licensable Model\n",
        "gptj = gpt4all.GPT4All('/content/drive/MyDrive/Talk_Data_GPT/gpt4all-converted.bin')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzhs5YToK_rp",
        "outputId": "f10ad24d-34c1-411f-d14c-2254c68a1ae9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found model file at  /content/drive/MyDrive/Talk_Data_GPT/gpt4all-converted.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Sample"
      ],
      "metadata": {
        "id": "xc_OMgMFvOZN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.1. Colors"
      ],
      "metadata": {
        "id": "xXNbVbweUR65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{'role': 'user', 'content': 'Name 3 colors'}]"
      ],
      "metadata": {
        "id": "cXSV_EJWHWH2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = gptj.chat_completion(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTOEBYnkHhmx",
        "outputId": "cfb154af-50b6-402c-c7eb-2150901f5232"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction: \n",
            "            The prompt below is a question to answer, a task to complete, or a conversation \n",
            "            to respond to; decide which and write an appropriate response.\n",
            "            \n",
            "### Prompt: \n",
            "Name 3 colors\n",
            "### Response:\n",
            "  \n",
            "Red, blue and green.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEQuhVteH6Ep",
        "outputId": "f57275bf-7010-4a9c-dfc8-e7167ca0fba2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': 'gpt4all-converted',\n",
              " 'usage': {'prompt_tokens': 239, 'completion_tokens': 23, 'total_tokens': 262},\n",
              " 'choices': [{'message': {'role': 'assistant',\n",
              "    'content': '  \\nRed, blue and green.'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.2. Roman Empire"
      ],
      "metadata": {
        "id": "ZTrSLriXIWHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{'role': 'user', 'content': 'What led to the collapse of the Roman Empire?'}]"
      ],
      "metadata": {
        "id": "sz9OzFufIZh7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = gptj.chat_completion(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09e35e57-6646-4c83-ba0f-605eb654b225",
        "id": "AAeeDMEGIZh8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction: \n",
            "            The prompt below is a question to answer, a task to complete, or a conversation \n",
            "            to respond to; decide which and write an appropriate response.\n",
            "            \n",
            "### Prompt: \n",
            "What led to the collapse of the Roman Empire?\n",
            "### Response:\n",
            "  \n",
            "A series of invasions by barbarian tribes, political instability and economic decline.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "252d4fce-321f-47e5-bae6-51c573330337",
        "id": "f29jOXLmIZh9"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': 'gpt4all-converted',\n",
              " 'usage': {'prompt_tokens': 271, 'completion_tokens': 89, 'total_tokens': 360},\n",
              " 'choices': [{'message': {'role': 'assistant',\n",
              "    'content': '  \\nA series of invasions by barbarian tribes, political instability and economic decline.'}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.3. Write Code"
      ],
      "metadata": {
        "id": "zgCRNuGtNWmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [{'role': 'user', 'content': 'How do I make a web request in Python?'}]"
      ],
      "metadata": {
        "id": "4gPcYNVNNWmv"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response = gptj.chat_completion(messages)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5485cf74-8182-4736-f0a5-c8c15bd1f9c6",
        "id": "GZyqSQ1hNWmw"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "### Instruction: \n",
            "            The prompt below is a question to answer, a task to complete, or a conversation \n",
            "            to respond to; decide which and write an appropriate response.\n",
            "            \n",
            "### Prompt: \n",
            "How do I make a web request in Python?\n",
            "### Response:\n",
            "  \n",
            "You can make a web request in Python using the requests library. You can use it to send HTTP GET or POST requests, and can also use it to send multipart/form-data requests. Here's an example:\n",
            "```python\n",
            "import requests\n",
            "response = requests.get('https://example.com')\n",
            "```\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b01cb1b-6e32-41a7-db2b-1be2a46ff85f",
        "id": "uv5UnaNRNWmx"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'model': 'gpt4all-converted',\n",
              " 'usage': {'prompt_tokens': 264,\n",
              "  'completion_tokens': 271,\n",
              "  'total_tokens': 535},\n",
              " 'choices': [{'message': {'role': 'assistant',\n",
              "    'content': \"  \\nYou can make a web request in Python using the requests library. You can use it to send HTTP GET or POST requests, and can also use it to send multipart/form-data requests. Here's an example:\\n```python\\nimport requests\\nresponse = requests.get('https://example.com')\\n```\"}}]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}